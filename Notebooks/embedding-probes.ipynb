{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3b76449-2d95-4567-b415-2755865b5057",
   "metadata": {},
   "source": [
    "<span style=\"font-size: xx-large; font-weight: bold;\">Graph embedding by Wasserstein similarity of clouds of depth-first probes</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a63f00-3d21-4962-ab8f-406e57be7471",
   "metadata": {},
   "source": [
    "Paul Burkhardt, Michael Gegick and Benoit Hamelin<br>\n",
    "November 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c38a5b-4caa-4997-a51d-0239e60e366c",
   "metadata": {},
   "source": [
    "# Context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29eed75c-11c1-45e7-846e-f41ad64e5f75",
   "metadata": {},
   "source": [
    "We seek to embed graphs in a vector space, in order to assess their similarity.\n",
    "We take inspiration from the Word2Vec word embedding, which represents each word as a distribution of random walks on a semantic similarity graph starting from this word."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6645d21-5bbc-409c-a7f9-453d6a9a6e78",
   "metadata": {},
   "source": [
    "Our focus here is that of an undirected graph $G=(V,E)$.\n",
    "We consider no edge weighting nor any value mapping to vertices: simple, naked graphs, but with each vertex being associated to an index from 0 to $|V|-1$.\n",
    "We propose to characterize a graph by a distribution of local observations of its topological structure.\n",
    "This observation takes the form of a *probe*: a depth-first walk on the graph initiated at some starting vertex $v \\in V$, limited to a maximum number of hops $M$.\n",
    "Let the probe be a sequence&nbsp;$p^v \\in \\mathbb{N}^M$, where $p^v_i$ constitutes the number of hops away from $v$ after $i$ steps into the depth-first walk; $p^v_0=0$.\n",
    "The walk takes a dive hop to any vertex only once.\n",
    "Given a choice between many vertices to dive towards, the walk dives to the vertex with smallest index.\n",
    "If all the deepward neighbors of a vertex $w$ have been visited, the walk takes a surfacing hop back along the path it dove on to get to $w$ at once.\n",
    "The walk terminates under either one of two conditions:\n",
    "\n",
    "1. The walk has surfaced back to vertex $v$, where it started, after a number of hops $n < M$: we then *pad* the walk by setting $p^v_j = -1$ for $n < j < M$;\n",
    "1. The walk has performed $M$ steps in total."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ca226-0dd1-45ef-b09f-57e91807b1b7",
   "metadata": {},
   "source": [
    "We propose to take $0 < N \\leq |V|$ such probes, each time starting from a distinct vertex sampled from a uniform distribution over the vertices not yet probed from.\n",
    "The resulting vectors of hop distances from their starting points are distinguished through a Levenshtein metric.\n",
    "Given that the probes taken from distinct vertices may be identical under certain conditions of local graph symmetry,\n",
    "the set of probes&nbsp;$P_N \\subset \\mathbb{N}^M$ is such that $|P_N| \\leq N$.\n",
    "Each probe $p \\in P_N$ is thus associated to a frequency of occurences&nbsp;$\\nu_p \\in \\mathbb{N}, \\nu_p \\leq 1, \\sum_{p\\in P_N} \\nu_p = N$.\n",
    "We may thus represent the result of probing the graph $G$ as a distribution&nbsp;$d[G, P_N]$ such that\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "d[G, P_N]:\\: & \\mathbb{N}^M & \\rightarrow & \\mathbb{R} \\\\\n",
    "             & p            & \\mapsto     & \\sum_{p \\in P_N} \\frac{\\nu_p}{N} \\delta(p - p^v)\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "where&nbsp;$\\delta(p)$ is the Dirac impulse function defined on $\\mathbb{N}^M$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369fecde-8503-4007-89a6-52cc09f1dd14",
   "metadata": {},
   "source": [
    "We assume that these distributions belong to a metric space where probes are related by the Levenshtein distance.\n",
    "This thus determines a characterization of a set of graphs by their corresponding distributions, which belong into a metric space where objects are related by the Wasserstein distance.\n",
    "The following code demonstrates how this vector space embedding may be implemented, and provides limited sanity checks in lieu of validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c96b07-505d-4aca-ba8e-9431903a8aed",
   "metadata": {},
   "source": [
    "# Imports and extension setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9acf52f5-699f-4267-91bd-131d80fd7276",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/vector/lib/python3.11/site-packages/umap/distances.py:1063: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/conda/envs/vector/lib/python3.11/site-packages/umap/distances.py:1071: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/conda/envs/vector/lib/python3.11/site-packages/umap/distances.py:1086: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/conda/envs/vector/lib/python3.11/site-packages/umap/umap_.py:660: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n",
      "/opt/conda/envs/vector/lib/python3.11/site-packages/umap/plot.py:203: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  @numba.jit()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.94 s, sys: 3.06 s, total: 9 s\n",
      "Wall time: 6.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from bokeh.io import output_notebook, show\n",
    "from concurrent.futures import as_completed\n",
    "import functools as ft\n",
    "import itertools as it\n",
    "import logging as lg\n",
    "import loky\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numba\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing as pre\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import *\n",
    "import umap\n",
    "import umap.plot\n",
    "from vectorizers import (\n",
    "    WassersteinVectorizer,\n",
    "    ApproximateWassersteinVectorizer,\n",
    "    SinkhornVectorizer,\n",
    ")\n",
    "from xxhash import xxh64_intdigest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d553e97-5c94-4ca0-a6dc-eb379989c4fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "        .bk-notebook-logo {\n",
       "            display: block;\n",
       "            width: 20px;\n",
       "            height: 20px;\n",
       "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
       "        }\n",
       "    </style>\n",
       "    <div>\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
       "        <span id=\"d9f8dfd0-cf34-44da-95c7-47d4d8863c48\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  const force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "const JS_MIME_TYPE = 'application/javascript';\n",
       "  const HTML_MIME_TYPE = 'text/html';\n",
       "  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  const CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    const script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    const cell = handle.cell;\n",
       "\n",
       "    const id = cell.output_area._bokeh_element_id;\n",
       "    const server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd_clean, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            const id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd_destroy);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    const output_area = handle.output_area;\n",
       "    const output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      const bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      const script_attrs = bk_div.children[0].attributes;\n",
       "      for (let i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      const toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    const events = require('base/js/events');\n",
       "    const OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  const NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    const el = document.getElementById(\"d9f8dfd0-cf34-44da-95c7-47d4d8863c48\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error(url) {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < css_urls.length; i++) {\n",
       "      const url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (let i = 0; i < js_urls.length; i++) {\n",
       "      const url = js_urls[i];\n",
       "      const element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error.bind(null, url);\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.1.min.js\", \"https://unpkg.com/@holoviz/panel@1.1.1/dist/panel.min.js\"];\n",
       "  const css_urls = [];\n",
       "\n",
       "  const inline_js = [    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "function(Bokeh) {\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "          for (let i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      const cell = $(document.getElementById(\"d9f8dfd0-cf34-44da-95c7-47d4d8863c48\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"d9f8dfd0-cf34-44da-95c7-47d4d8863c48\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.1.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.1.1.min.js\", \"https://unpkg.com/@holoviz/panel@1.1.1/dist/panel.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"d9f8dfd0-cf34-44da-95c7-47d4d8863c48\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "output_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fa452af-a073-429b-a113-0079132d0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.basicConfig(\n",
    "    format=\"%(asctime)s | %(levelname)-8s | %(name)15s | %(message)s\",\n",
    "    datefmt=\"%H:%M:%S\",\n",
    "    level=lg.WARNING\n",
    ")\n",
    "lg.getLogger(\"graphs2vecs\").setLevel(lg.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a19062-e36c-4b79-afcc-fe7085221f49",
   "metadata": {},
   "source": [
    "# Probing graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec494936-ec07-456f-bafd-78f7cc9a9bbb",
   "metadata": {},
   "source": [
    "Probes will be stored as integer Numpy arrays.\n",
    "However, such arrays are not _hashable_ in the Python sense, although this is very convenient for assembling distributions.\n",
    "We will thus wrap these arrays in a bespoke `Probe` class, which provides hashing and a less pendantic equality comparison (which stands thanks to our arrays being composed of integers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e718ddf-c4f3-4df8-9e2c-94e576f3497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe(np.ndarray):\n",
    "\n",
    "    def __hash__(self) -> int:\n",
    "        return xxh64_intdigest(self)\n",
    "\n",
    "    def __eq__(self, other: Any) -> bool:\n",
    "        if not isinstance(other, Probe):\n",
    "            return False\n",
    "        return hash(self) == hash(other)\n",
    "\n",
    "\n",
    "def mkprobe(dists: List[int]) -> Probe:\n",
    "    return np.array(dists, dtype=int).view(Probe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec99d98-fe94-4542-9056-7598a88aaa1f",
   "metadata": {},
   "source": [
    "The following routine articulates the walk algorithm expressed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c58543f-bf39-43b3-91f0-c78b64f8f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_depth_first(g: nx.Graph, vertex_start: int, max_length: int) -> Probe:\n",
    "    visit = []\n",
    "    visited = {vertex_start}\n",
    "    stack = [vertex_start]\n",
    "    while len(visit) < max_length and stack:\n",
    "        visit.append(len(stack) - 1)\n",
    "        for neighbor in g.neighbors(stack[-1]):\n",
    "            if neighbor not in visited:\n",
    "                visited.add(neighbor)\n",
    "                stack.append(neighbor)\n",
    "                break\n",
    "        else:\n",
    "            stack.pop()\n",
    "\n",
    "    return mkprobe(visit + [-1] * (max_length - len(visit)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3217f7c3-3c3b-4e3b-a899-3763c42f68f4",
   "metadata": {},
   "source": [
    "We mean to probe a graph multiple times, which as was evoked, results in the same probe vector being generated from symmetrical starting vertices.\n",
    "Once all probes have been computed for a graph, we thus group them and count their multiplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00c4761-eb6d-4752-84ea-43842018b09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probe_graph(\n",
    "    g: nx.Graph,\n",
    "    max_length: int,\n",
    "    num_probes: int = 0,\n",
    ") -> Iterator[Tuple[int, Probe]]:\n",
    "    N = nx.number_of_nodes(g)\n",
    "    if num_probes < 1 or num_probes > N:\n",
    "        num_probes = N\n",
    "    probes = sorted(\n",
    "        [\n",
    "            probe_depth_first(g, v, max_length)\n",
    "            for v in np.random.choice(g.nodes, size=num_probes, replace=False)\n",
    "        ],\n",
    "        key=hash\n",
    "    )\n",
    "\n",
    "    for _, i_probes in it.groupby(probes, key=hash):\n",
    "        probes = list(i_probes)\n",
    "        assert probes\n",
    "        yield len(probes), probes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c24e69-f88f-448e-8e91-813fdc6d49bb",
   "metadata": {},
   "source": [
    "# From probes to distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02174437-a992-4f6b-b7d7-0fee5f4398f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ProbeDistribution = Tuple[np.ndarray, Sequence[np.ndarray]]\n",
    "TrackerProgress = Callable[..., Iterator]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a7bc36-dcc9-44f6-a7f5-ac7615ad1aa5",
   "metadata": {},
   "source": [
    "Now, probes even repeat over a set of graphs, further establishing the notion of the distribution as a great characterization for tracking their similarity.\n",
    "The following routines tracks the set of probes computed out of a set of graphs, providing both the distribution frequencies (the critical $\\nu_p$ parameters) and the set of probes shared among the graphs.\n",
    "\n",
    "A note here regarding probe length: it is obvious that a depth-first walk that dives to a node no more than once has maximum useful length determined by the number of nodes to the graph.\n",
    "At this step, where all the graphs involved in a similarity analysis task are provided, it is useful to provide this limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357d6e0c-9359-4dfb-9e23-99b56bab2529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs_as_distributions_probes(\n",
    "    graphs: Sequence[nx.Graph],\n",
    "    max_length: int = 0,\n",
    "    num_probes: int = 0,\n",
    "    tqdm: TrackerProgress = lambda x, *_a, **_k: iter(x)\n",
    ") -> ProbeDistribution:\n",
    "    M = 2 * max(nx.number_of_nodes(g) for g in graphs) - 1\n",
    "    if max_length < 2 or max_length > M:\n",
    "        max_length = M\n",
    "\n",
    "    index_probes = {}\n",
    "    probes = []\n",
    "    distributions = np.zeros((len(graphs), 0))\n",
    "    for i, g in enumerate(tqdm(graphs, desc=\"Graph probing\")):\n",
    "        if i%500==0:\n",
    "            print(i)\n",
    "        for n, probe in probe_graph(g, max_length=max_length, num_probes=num_probes):\n",
    "            if probe in index_probes:\n",
    "                j = index_probes[probe]\n",
    "            else:\n",
    "                j = len(index_probes)\n",
    "                index_probes[probe] = j\n",
    "                probes.append(probe)\n",
    "                distributions = np.hstack([\n",
    "                    distributions,\n",
    "                    np.zeros((distributions.shape[0], 1)),\n",
    "                ])\n",
    "            distributions[i, j] = float(n)\n",
    "\n",
    "    return (pre.normalize(distributions, axis=1, norm=\"l1\"), probes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dd6050-f969-4882-9d07-18e3086dd548",
   "metadata": {},
   "source": [
    "# From distributions to a vector space embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27de3b82-8022-43e3-b263-cea9b1475e6b",
   "metadata": {},
   "source": [
    "We propose that the probes making up a distribution should be inscribed in a metric space based on the Levenshtein distance.\n",
    "Here is a good Numba implementation ripped from [the Internet](https://gist.github.com/tuxedocat/fb024dfa36648797084d)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a53954f3-13f7-4f00-a80e-ebda8764da91",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def _levenshtein(x, y):\n",
    "    \"\"\" Levenshtein distance\n",
    "          using Dynamic-Programming strategy\n",
    "    Parameters\n",
    "    ----------\n",
    "    x, y : np.array of string\n",
    "    Returns\n",
    "    -------\n",
    "    int : distance\n",
    "    np.array : distance matrix\n",
    "    \"\"\"\n",
    "    # Initiallize DP-matrix\n",
    "    D = np.zeros((len(x) + 1, len(y) + 1), dtype=np.int64)\n",
    "    D[0, 1:] = np.arange(1, len(y) + 1)\n",
    "    D[1:, 0] = np.arange(1, len(x) + 1)\n",
    "\n",
    "    for i in range(1, len(x) + 1):\n",
    "        for j in range(1, len(y) + 1):\n",
    "            delta = 2 if x[i - 1] != y[j - 1] else 0\n",
    "            D[i, j] = min(D[i - 1, j - 1] + delta, D[i - 1, j] + 1, D[i, j - 1] + 1)\n",
    "    return D[-1, -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45043147-0568-48e1-a8c0-37ff737349da",
   "metadata": {},
   "source": [
    "This metric space enables us to embed the distributions themselves into their own metric space based on the Wasserstein distance.\n",
    "This gives us an end-to-end routine that takes a set of graphs and probing parameters, and yields a corresponding set of vectors (embedded in a Euclidean metric space)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "571a5fa1-ffc4-4c47-812f-6820d1302e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def graphs2vecs(\n",
    "    graphs: Sequence[nx.Graph],\n",
    "    max_length: int = 0,\n",
    "    num_probes: int = 0,\n",
    "    tqdm: TrackerProgress = lambda x, *_, **__: iter(x),\n",
    "    vectorizer: Type = WassersteinVectorizer,\n",
    "    **args_wv\n",
    ") -> np.ndarray:\n",
    "    LOG = lg.getLogger(\"graphs2vecs\")\n",
    "    LOG.info(\"Probe the graphs\")\n",
    "    distributions, probes = graphs_as_distributions_probes(\n",
    "        graphs,\n",
    "        max_length=max_length,\n",
    "        num_probes=num_probes,\n",
    "        tqdm=tqdm\n",
    "    )\n",
    "\n",
    "    args_wv[\"n_components\"] = max(\n",
    "        args_wv.get(\"n_components\", 0),\n",
    "        2 * max(len(v) for v in probes)\n",
    "    )\n",
    "    args_wv.setdefault(\"metric\", _levenshtein)\n",
    "    LOG.info(\"Calculate Wasserstein vectorization\")\n",
    "    return WassersteinVectorizer(**args_wv).fit_transform(\n",
    "        distributions,\n",
    "        vectors=probes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334785d6-d861-4742-b192-8f874d3bc789",
   "metadata": {},
   "source": [
    "# Eyeballing the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea3af1-de83-4afe-8fae-3df56c62b4f3",
   "metadata": {},
   "source": [
    "While we are interested in embedding quite large graphs with this approach, this first implementation leverages unoptimized, easy-to-use tools.\n",
    "As such, I surmise that this code would not be snappy with graphs as small as the 500-vertex range.\n",
    "So let's instead examine the embeddings of a subset of the small graphs that make up NetworkX's graph atlas."
   ]
  },
  {
   "cell_type": "raw",
   "id": "014590b8",
   "metadata": {},
   "source": [
    "def gen_atlas(min_nodes, min_edges, min_nodes_per_cc):\n",
    "    return [\n",
    "        g\n",
    "        for g in nx.graph_atlas_g()\n",
    "        if (\n",
    "            nx.number_of_nodes(g) >= min_nodes\n",
    "            and nx.number_of_edges(g) >= min_edges\n",
    "            and all(len(cv) >= min_nodes_per_cc for cv in nx.connected_components(g))\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f4b9318",
   "metadata": {},
   "source": [
    "%%time\n",
    "atlas = gen_atlas(4, 3, 2)\n",
    "len(atlas)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac858257",
   "metadata": {},
   "source": [
    "atlas[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec689e-aa21-4593-b42f-54ad7486ab2e",
   "metadata": {},
   "source": [
    "These graphs are composed of no more than 7 vertices, we insist on having a non-trivial edge set, and we restrict connected components to carry at least two vertices.\n",
    "In this situation, most of these graphs look very similar from the structural perspective we have taken.\n",
    "Each graph admits at most 7 distinct probes: let's make them long enough to ensure that each can cover all of a unique connected component.\n",
    "Before we compute vectors, let's look at how many distinct probes characterize our 1000ish graphs:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7dc54d70",
   "metadata": {},
   "source": [
    "distr, probes = graphs_as_distributions_probes(atlas)\n",
    "len(probes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4892e0c-7ea7-432b-b833-634740fc4137",
   "metadata": {},
   "source": [
    "So the \"vocabulary\" that describes each graph is composed of less than 20% the number of graphs themselves.\n",
    "I believe the situation would be quite different from the large graph embedding being considered as target application for this approach.\n",
    "The number of edges in such cases would be such that it would be very unlikely to hop over all of them, unless one would afford a large number of long probes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e5c2b4-1b9c-4222-8992-12572d90eda9",
   "metadata": {},
   "source": [
    "Let's embed:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0210f7e",
   "metadata": {},
   "source": [
    "%%time\n",
    "emb = graphs2vecs(atlas, n_components=128, tqdm=tqdm)\n",
    "emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc34ddb",
   "metadata": {},
   "source": [
    "## Probes for our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "cd0df84e-c63c-4273-92e6-83cefc553b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig\n",
    "\n",
    "dataset = 'REDDIT-BINARY'\n",
    "datadir = './EmbeddingOfGraphs-main/Data/'+dataset+'/'+dataset\n",
    "#has_node_labels = False\n",
    "\n",
    "## read data from folder\n",
    "fn_edges = datadir+'.edges'\n",
    "fn_graph_id = datadir+'.graph_id'\n",
    "#fn_graph_label = datadir+'.graph_labels'\n",
    "#fn_node_label = datadir+'.node_labels'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "16671c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read edges, build overall graph\n",
    "with open(fn_edges) as f:\n",
    "    E = [tuple(map(int,x.strip().split(','))) for x in f.readlines()]\n",
    "G = ig.Graph.TupleList(E, directed=True).as_undirected()\n",
    "\n",
    "## read subgraph node memberships (subgraphs names are 1-based)\n",
    "with open(fn_graph_id) as f:\n",
    "    sg_mem = [int(x.strip())-1 for x in f.readlines()]\n",
    "\n",
    "## build dictionary (node names are 1-based)\n",
    "graph_dict = {(x+1):y for x,y in enumerate(sg_mem)}\n",
    "for v in G.vs:\n",
    "    v['graph'] = graph_dict[v['name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1e319d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "## map to networkx\n",
    "NXG = []\n",
    "for i in range(0,max(G.vs['graph'])+1):\n",
    "    sg = G.subgraph(np.where(np.array(G.vs['graph']) == i)[0].tolist()).connected_components().giant()\n",
    "    NXG.append(sg.to_networkx())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ea414d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:29:18 | INFO     |     graphs2vecs | Probe the graphs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8707b9689d04a42af7adf574e70b6bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Graph probing:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:07:58 | INFO     |     graphs2vecs | Calculate Wasserstein vectorization\n"
     ]
    }
   ],
   "source": [
    "## call the probing function\n",
    "emb = graphs2vecs(NXG, n_components=128, tqdm=tqdm, max_length=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4abff4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save embedding\n",
    "import pickle\n",
    "with open('probes_20_'+dataset+'.pkl','wb') as fp:\n",
    "    pickle.dump( emb, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91256a30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:vector]",
   "language": "python",
   "name": "conda-env-vector-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
